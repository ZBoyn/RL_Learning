{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "[[b'S' b'F' b'F' b'F']\n",
      " [b'F' b'H' b'F' b'H']\n",
      " [b'F' b'F' b'F' b'H']\n",
      " [b'H' b'F' b'F' b'G']]\n",
      "冰洞的索引: {5, 7, 11, 12}\n",
      "目标的索引: {15}\n",
      "[(0.3333333333333333, 10, 0.0, False), (0.3333333333333333, 13, 0.0, False), (0.3333333333333333, 14, 0.0, False)]\n",
      "[(0.3333333333333333, 13, 0.0, False), (0.3333333333333333, 14, 0.0, False), (0.3333333333333333, 15, 1.0, True)]\n",
      "[(0.3333333333333333, 14, 0.0, False), (0.3333333333333333, 15, 1.0, True), (0.3333333333333333, 10, 0.0, False)]\n",
      "[(0.3333333333333333, 15, 1.0, True), (0.3333333333333333, 10, 0.0, False), (0.3333333333333333, 13, 0.0, False)]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make(\"FrozenLake-v1\")  # 创建环境\n",
    "env = env.unwrapped  # 解封装才能访问状态转移矩阵P\n",
    "print(env.ncol)\n",
    "print(env.nrow)\n",
    "print(env.desc)\n",
    "\n",
    "holes = set()\n",
    "ends = set()\n",
    "for s in env.P:\n",
    "    for a in env.P[s]:\n",
    "        for s_ in env.P[s][a]:\n",
    "            # s_格式: (prob, next_state, reward, done)\n",
    "            if s_[2] == 1.0:\n",
    "                ends.add(s_[1])\n",
    "            if s_[3] is True:\n",
    "                holes.add(s_[1])\n",
    "holes -= ends\n",
    "print(\"冰洞的索引:\", holes)\n",
    "print(\"目标的索引:\", ends)\n",
    "\n",
    "for a in env.P[14]:\n",
    "    print(env.P[14][a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration:\n",
    "    def __init__(self, env, theta, gamma):\n",
    "        self.env = env\n",
    "        self.v = [0] * env.ncol * env.nrow\n",
    "        self.theta = theta\n",
    "        self.gamma = gamma\n",
    "        # 初始化策略\n",
    "        self.pi = [0] * env.ncol * env.nrow\n",
    "    \n",
    "    def value_iteration(self):\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            delta = 0\n",
    "            new_v = [0] * self.env.ncol * self.env.nrow\n",
    "            for s in range(self.env.ncol * self.env.nrow):\n",
    "                qsa_list = []\n",
    "                for a in range(4):\n",
    "                    qsa = 0\n",
    "                    for s_ in self.env.P[s][a]:\n",
    "                        qsa += s_[0] * (s_[2] + self.gamma * self.v[s_[1]] * (1 - s_[3]))\n",
    "                    qsa_list.append(qsa)\n",
    "                new_v[s] = max(qsa_list)\n",
    "                delta = max(delta, abs(new_v[s] - self.v[s]))\n",
    "            self.v = new_v\n",
    "            if delta < self.theta:\n",
    "                break\n",
    "            cnt += 1\n",
    "        print(\"迭代次数:\", cnt)\n",
    "        self.get_policy()\n",
    "        \n",
    "    def get_policy(self):\n",
    "        for s in range(self.env.ncol * self.env.nrow):\n",
    "            qsa_list = []\n",
    "            for a in range(4):\n",
    "                qsa = 0\n",
    "                for s_ in self.env.P[s][a]:\n",
    "                    qsa += s_[0] * (s_[2] + self.gamma * self.v[s_[1]] * (1 - s_[3]))\n",
    "                qsa_list.append(qsa)\n",
    "            maxq = max(qsa_list)\n",
    "            cntq = qsa_list.count(maxq)\n",
    "            # 平分最大值\n",
    "            self.pi[s] = [1 / cntq if q == maxq else 0 for q in qsa_list]\n",
    "        print(\"策略:\", self.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_agent(agent, action_meaning, disaster=[], end=[]):\n",
    "    print(\"状态价值：\")\n",
    "    for i in range(agent.env.nrow):\n",
    "        for j in range(agent.env.ncol):\n",
    "            # 为了输出美观,保持输出6个字符\n",
    "            print('%6.6s' % ('%.3f' % agent.v[i * agent.env.ncol + j]), end=' ')\n",
    "        print()\n",
    "\n",
    "    print(\"策略：\")\n",
    "    for i in range(agent.env.nrow):\n",
    "        for j in range(agent.env.ncol):\n",
    "            # 一些特殊的状态,例如悬崖漫步中的悬崖\n",
    "            if (i * agent.env.ncol + j) in disaster:\n",
    "                print('****', end=' ')\n",
    "            elif (i * agent.env.ncol + j) in end:  # 目标状态\n",
    "                print('EEEE', end=' ')\n",
    "            else:\n",
    "                a = agent.pi[i * agent.env.ncol + j]\n",
    "                pi_str = ''\n",
    "                for k in range(len(action_meaning)):\n",
    "                    pi_str += action_meaning[k] if a[k] > 0 else 'o'\n",
    "                print(pi_str, end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代次数: 60\n",
      "策略: [[1.0, 0, 0, 0], [0, 0, 0, 1.0], [1.0, 0, 0, 0], [0, 0, 0, 1.0], [1.0, 0, 0, 0], [0.25, 0.25, 0.25, 0.25], [0.5, 0, 0.5, 0], [0.25, 0.25, 0.25, 0.25], [0, 0, 0, 1.0], [0, 1.0, 0, 0], [1.0, 0, 0, 0], [0.25, 0.25, 0.25, 0.25], [0.25, 0.25, 0.25, 0.25], [0, 0, 1.0, 0], [0, 1.0, 0, 0], [0.25, 0.25, 0.25, 0.25]]\n",
      "状态价值：\n",
      " 0.069  0.061  0.074  0.056 \n",
      " 0.092  0.000  0.112  0.000 \n",
      " 0.145  0.247  0.300  0.000 \n",
      " 0.000  0.380  0.639  0.000 \n",
      "策略：\n",
      "<ooo ooo^ <ooo ooo^ \n",
      "<ooo **** <o>o **** \n",
      "ooo^ ovoo <ooo **** \n",
      "**** oo>o ovoo EEEE \n"
     ]
    }
   ],
   "source": [
    "action_meaning = ['<', 'v', '>', '^']\n",
    "theta = 1e-5\n",
    "gamma = 0.9\n",
    "agent = ValueIteration(env, theta, gamma)\n",
    "agent.value_iteration()\n",
    "print_agent(agent, action_meaning, disaster=holes, end=ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
